{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Ingest Orchestration via SageMaker Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Application Code using SageMaker Python SDK to ingest the pandas dataframe. This is run in the SageMaker Processing Container"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile fs_batch_ingest.py\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sagemaker\"])\n",
    "import sagemaker as sm\n",
    "\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sm_session = Session()       \n",
    "\n",
    "def cast_object_to_string(df):\n",
    "    for col in df.columns:\n",
    "        if df.dtypes[col] == 'object':\n",
    "            df[col] = df[col].astype('str')\n",
    "\n",
    "\n",
    "def ingest_data(args):   \n",
    "\n",
    "    file_list = glob.glob('/opt/ml/processing/input/*.csv')\n",
    "    df = pd.concat([pd.read_csv(f) for f in file_list], ignore_index=True)\n",
    "    cast_object_to_string(df)\n",
    "\n",
    "    fg = FeatureGroup(name=args.feature_group_name, sagemaker_session=sm_session)\n",
    "    resp = fg.ingest(data_frame=df, max_processes=args.num_processes, max_workers=args.num_workers, wait=True)\n",
    "    \n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--num_processes\", type=int, default=1)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=1)\n",
    "    parser.add_argument(\"--feature_group_name\", type=str, required=True)\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    ingest_data(args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Please gather the s3 location for chunked files and the Feature Group Name that is provisioned earlier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "s3_uri_prefix = 's3://fs-ingest-2/data/chunks-1M/'\n",
    "feature_group_name = 'ingest-fg-06-17-2021-14-46-44'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sample Config for SageMaker Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "instance_config = {\n",
    "        'instance_type': 'ml.m5.4xlarge',\n",
    "        'instance_count': 5,\n",
    "        'num_processes': '16',\n",
    "        'num_workers': '4'\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Orchestrate ingestion using SageMaker Processing Job\n",
    "\n",
    "see logs for sagemaker processing jobs (please update your region in the url) - https://us-west-2.console.aws.amazon.com/sagemaker/home?region=us-west-2#/processing-jobs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',role=get_execution_role(),\n",
    "                             instance_type=instance_config['instance_type'],\n",
    "                             instance_count=instance_config['instance_count'],\n",
    "                             env={'AWS_DEFAULT_REGION': boto3.Session().region_name})\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code='fs_batch_ingest.py',\n",
    "    arguments = ['--num_processes', instance_config['num_processes'], \n",
    "                 '--num_workers', instance_config['num_workers'],\n",
    "                 '--feature_group_name', feature_group_name],\n",
    "    inputs=[ProcessingInput(\n",
    "        s3_data_type='S3Prefix',\n",
    "        source=s3_uri_prefix,\n",
    "        s3_data_distribution_type='ShardedByS3Key',\n",
    "        destination='/opt/ml/processing/input')],\n",
    "    logs=False\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}